{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Built in conda environment with python 3.7\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "# Load Data\n",
    "data = pd.read_csv('dataset/spam.csv', encoding ='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ham</td>\n",
       "      <td>I'm gonna be home soon and i don't want to tal...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>spam</td>\n",
       "      <td>SIX chances to win CASH! From 100 to 20,000 po...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>spam</td>\n",
       "      <td>URGENT! You have won a 1 week FREE membership ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ham</td>\n",
       "      <td>I've been searching for the right words to tha...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>spam</td>\n",
       "      <td>XXXMobileMovieClub: To use your credit, click ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ham</td>\n",
       "      <td>Oh k...i'm watching here:)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ham</td>\n",
       "      <td>Eh u remember how 2 spell his name... Yes i di...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ham</td>\n",
       "      <td>Fine if thatåÕs the way u feel. ThatåÕs the wa...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>spam</td>\n",
       "      <td>England v Macedonia - dont miss the goals/team...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ham</td>\n",
       "      <td>Is that seriously how you spell his name?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ham</td>\n",
       "      <td>IÛ÷m going to try for 2 months ha ha only joking</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ham</td>\n",
       "      <td>So Ì_ pay first lar... Then when is da stock c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ham</td>\n",
       "      <td>Aft i finish my lunch then i go str down lor. ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ffffffffff. Alright no way I can meet up with ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ham</td>\n",
       "      <td>Just forced myself to eat a slice. I'm really ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ham</td>\n",
       "      <td>Lol your always so convincing.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ham</td>\n",
       "      <td>Did you catch the bus ? Are you frying an egg ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ham</td>\n",
       "      <td>I'm back &amp;amp; we're packing the car now, I'll...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ahhh. Work. I vaguely remember that! What does...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5542</th>\n",
       "      <td>ham</td>\n",
       "      <td>Armand says get your ass over to epsilon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5543</th>\n",
       "      <td>ham</td>\n",
       "      <td>U still havent got urself a jacket ah?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5544</th>\n",
       "      <td>ham</td>\n",
       "      <td>I'm taking derek &amp;amp; taylor to walmart, if I...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5545</th>\n",
       "      <td>ham</td>\n",
       "      <td>Hi its in durban are you still on this number</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5546</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ic. There are a lotta childporn cars then.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5547</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your contract mobile 11 Mnths? Latest Moto...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5548</th>\n",
       "      <td>ham</td>\n",
       "      <td>No, I was trying it all weekend ;V</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5549</th>\n",
       "      <td>ham</td>\n",
       "      <td>You know, wot people wear. T shirts, jumpers, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5550</th>\n",
       "      <td>ham</td>\n",
       "      <td>Cool, what time you think you can get here?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5551</th>\n",
       "      <td>ham</td>\n",
       "      <td>Wen did you get so spiritual and deep. That's ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5552</th>\n",
       "      <td>ham</td>\n",
       "      <td>Have a safe trip to Nigeria. Wish you happines...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5553</th>\n",
       "      <td>ham</td>\n",
       "      <td>Hahaha..use your brain dear</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5554</th>\n",
       "      <td>ham</td>\n",
       "      <td>Well keep in mind I've only got enough gas for...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5555</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yeh. Indians was nice. Tho it did kane me off ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5556</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yes i have. So that's why u texted. Pshew...mi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5557</th>\n",
       "      <td>ham</td>\n",
       "      <td>No. I meant the calculation is the same. That ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5558</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5559</th>\n",
       "      <td>ham</td>\n",
       "      <td>if you aren't here in the next  &amp;lt;#&amp;gt;  hou...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5560</th>\n",
       "      <td>ham</td>\n",
       "      <td>Anything lor. Juz both of us lor.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5561</th>\n",
       "      <td>ham</td>\n",
       "      <td>Get me out of this dump heap. My mom decided t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5562</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lor... Sony ericsson salesman... I ask shuh...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5563</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ard 6 like dat lor.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5564</th>\n",
       "      <td>ham</td>\n",
       "      <td>Why don't you wait 'til at least wednesday to ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5565</th>\n",
       "      <td>ham</td>\n",
       "      <td>Huh y lei...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5566</th>\n",
       "      <td>spam</td>\n",
       "      <td>REMINDER FROM O2: To get 2.50 pounds free call...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        v1                                                 v2 Unnamed: 2  \\\n",
       "0      ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1      ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3      ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "5     spam  FreeMsg Hey there darling it's been 3 week's n...        NaN   \n",
       "6      ham  Even my brother is not like to speak with me. ...        NaN   \n",
       "7      ham  As per your request 'Melle Melle (Oru Minnamin...        NaN   \n",
       "8     spam  WINNER!! As a valued network customer you have...        NaN   \n",
       "9     spam  Had your mobile 11 months or more? U R entitle...        NaN   \n",
       "10     ham  I'm gonna be home soon and i don't want to tal...        NaN   \n",
       "11    spam  SIX chances to win CASH! From 100 to 20,000 po...        NaN   \n",
       "12    spam  URGENT! You have won a 1 week FREE membership ...        NaN   \n",
       "13     ham  I've been searching for the right words to tha...        NaN   \n",
       "14     ham                I HAVE A DATE ON SUNDAY WITH WILL!!        NaN   \n",
       "15    spam  XXXMobileMovieClub: To use your credit, click ...        NaN   \n",
       "16     ham                         Oh k...i'm watching here:)        NaN   \n",
       "17     ham  Eh u remember how 2 spell his name... Yes i di...        NaN   \n",
       "18     ham  Fine if thatåÕs the way u feel. ThatåÕs the wa...        NaN   \n",
       "19    spam  England v Macedonia - dont miss the goals/team...        NaN   \n",
       "20     ham          Is that seriously how you spell his name?        NaN   \n",
       "21     ham  IÛ÷m going to try for 2 months ha ha only joking        NaN   \n",
       "22     ham  So Ì_ pay first lar... Then when is da stock c...        NaN   \n",
       "23     ham  Aft i finish my lunch then i go str down lor. ...        NaN   \n",
       "24     ham  Ffffffffff. Alright no way I can meet up with ...        NaN   \n",
       "25     ham  Just forced myself to eat a slice. I'm really ...        NaN   \n",
       "26     ham                     Lol your always so convincing.        NaN   \n",
       "27     ham  Did you catch the bus ? Are you frying an egg ...        NaN   \n",
       "28     ham  I'm back &amp; we're packing the car now, I'll...        NaN   \n",
       "29     ham  Ahhh. Work. I vaguely remember that! What does...        NaN   \n",
       "...    ...                                                ...        ...   \n",
       "5542   ham           Armand says get your ass over to epsilon        NaN   \n",
       "5543   ham             U still havent got urself a jacket ah?        NaN   \n",
       "5544   ham  I'm taking derek &amp; taylor to walmart, if I...        NaN   \n",
       "5545   ham      Hi its in durban are you still on this number        NaN   \n",
       "5546   ham         Ic. There are a lotta childporn cars then.        NaN   \n",
       "5547  spam  Had your contract mobile 11 Mnths? Latest Moto...        NaN   \n",
       "5548   ham                 No, I was trying it all weekend ;V        NaN   \n",
       "5549   ham  You know, wot people wear. T shirts, jumpers, ...        NaN   \n",
       "5550   ham        Cool, what time you think you can get here?        NaN   \n",
       "5551   ham  Wen did you get so spiritual and deep. That's ...        NaN   \n",
       "5552   ham  Have a safe trip to Nigeria. Wish you happines...        NaN   \n",
       "5553   ham                        Hahaha..use your brain dear        NaN   \n",
       "5554   ham  Well keep in mind I've only got enough gas for...        NaN   \n",
       "5555   ham  Yeh. Indians was nice. Tho it did kane me off ...        NaN   \n",
       "5556   ham  Yes i have. So that's why u texted. Pshew...mi...        NaN   \n",
       "5557   ham  No. I meant the calculation is the same. That ...        NaN   \n",
       "5558   ham                             Sorry, I'll call later        NaN   \n",
       "5559   ham  if you aren't here in the next  &lt;#&gt;  hou...        NaN   \n",
       "5560   ham                  Anything lor. Juz both of us lor.        NaN   \n",
       "5561   ham  Get me out of this dump heap. My mom decided t...        NaN   \n",
       "5562   ham  Ok lor... Sony ericsson salesman... I ask shuh...        NaN   \n",
       "5563   ham                                Ard 6 like dat lor.        NaN   \n",
       "5564   ham  Why don't you wait 'til at least wednesday to ...        NaN   \n",
       "5565   ham                                       Huh y lei...        NaN   \n",
       "5566  spam  REMINDER FROM O2: To get 2.50 pounds free call...        NaN   \n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...        NaN   \n",
       "5568   ham              Will Ì_ b going to esplanade fr home?        NaN   \n",
       "5569   ham  Pity, * was in mood for that. So...any other s...        NaN   \n",
       "5570   ham  The guy did some bitching but I acted like i'd...        NaN   \n",
       "5571   ham                         Rofl. Its true to its name        NaN   \n",
       "\n",
       "     Unnamed: 3 Unnamed: 4  \n",
       "0           NaN        NaN  \n",
       "1           NaN        NaN  \n",
       "2           NaN        NaN  \n",
       "3           NaN        NaN  \n",
       "4           NaN        NaN  \n",
       "5           NaN        NaN  \n",
       "6           NaN        NaN  \n",
       "7           NaN        NaN  \n",
       "8           NaN        NaN  \n",
       "9           NaN        NaN  \n",
       "10          NaN        NaN  \n",
       "11          NaN        NaN  \n",
       "12          NaN        NaN  \n",
       "13          NaN        NaN  \n",
       "14          NaN        NaN  \n",
       "15          NaN        NaN  \n",
       "16          NaN        NaN  \n",
       "17          NaN        NaN  \n",
       "18          NaN        NaN  \n",
       "19          NaN        NaN  \n",
       "20          NaN        NaN  \n",
       "21          NaN        NaN  \n",
       "22          NaN        NaN  \n",
       "23          NaN        NaN  \n",
       "24          NaN        NaN  \n",
       "25          NaN        NaN  \n",
       "26          NaN        NaN  \n",
       "27          NaN        NaN  \n",
       "28          NaN        NaN  \n",
       "29          NaN        NaN  \n",
       "...         ...        ...  \n",
       "5542        NaN        NaN  \n",
       "5543        NaN        NaN  \n",
       "5544        NaN        NaN  \n",
       "5545        NaN        NaN  \n",
       "5546        NaN        NaN  \n",
       "5547        NaN        NaN  \n",
       "5548        NaN        NaN  \n",
       "5549        NaN        NaN  \n",
       "5550        NaN        NaN  \n",
       "5551        NaN        NaN  \n",
       "5552        NaN        NaN  \n",
       "5553        NaN        NaN  \n",
       "5554        NaN        NaN  \n",
       "5555        NaN        NaN  \n",
       "5556        NaN        NaN  \n",
       "5557        NaN        NaN  \n",
       "5558        NaN        NaN  \n",
       "5559        NaN        NaN  \n",
       "5560        NaN        NaN  \n",
       "5561        NaN        NaN  \n",
       "5562        NaN        NaN  \n",
       "5563        NaN        NaN  \n",
       "5564        NaN        NaN  \n",
       "5565        NaN        NaN  \n",
       "5566        NaN        NaN  \n",
       "5567        NaN        NaN  \n",
       "5568        NaN        NaN  \n",
       "5569        NaN        NaN  \n",
       "5570        NaN        NaN  \n",
       "5571        NaN        NaN  \n",
       "\n",
       "[5572 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop empty tables\n",
    "data = data.drop([\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = data['v2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\srder\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk \n",
    "\n",
    "# Use to download stopwords \n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def ProcessText(text, remove_stops = True, lower_case = True):\n",
    "    '''\n",
    "        Quick text preprocessing for single list of text, remove stopwords, non-letters, handle upper/lowercases and non-words\n",
    "    '''\n",
    "\n",
    "    if lower_case == True:\n",
    "        text = text.lower()\n",
    "\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    if len(text) > 0:\n",
    "        text = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "        if remove_stops == True:\n",
    "            text = ' '.join([w for w in text.split() if not w in stops])\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Progress - 2999 of 5572"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Progress - 5571 of 5572\n",
      "Time taken - 4.479146463796225\n"
     ]
    }
   ],
   "source": [
    "import timeit \n",
    "import sys \n",
    "\n",
    "# Process all emails in data \n",
    "processed_corpus = []\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "for progress, email in enumerate(corpus):\n",
    "    processed_corpus.append(ProcessText(email, remove_stops = True, lower_case = True))\n",
    "    sys.stdout.write('\\r' + ' Progress - ' + str(progress) + ' of ' + str(len(corpus)))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "print('')\n",
    "print('Time taken -', timeit.default_timer() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay name ur price as long as its legal! Wen can I pick them up? Y u ave x ams xx\n",
      "\n",
      "okay name ur price long legal wen pick u ave x ams xx\n"
     ]
    }
   ],
   "source": [
    "# Compare emails vs processed emails \n",
    "print(corpus[100])\n",
    "print('')\n",
    "print(processed_corpus[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count all words \n",
    "from collections import Counter \n",
    "\n",
    "flattened_emails = []\n",
    "for processed_email in processed_corpus:\n",
    "    for word in processed_email.split():\n",
    "        flattened_emails.append(word)\n",
    "        \n",
    "word_counts = Counter(flattened_emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words 7564\n",
      "\n",
      "Top 10 words\n",
      "('u', 1212)\n",
      "('call', 606)\n",
      "('get', 397)\n",
      "('ur', 385)\n",
      "('gt', 318)\n",
      "('lt', 316)\n",
      "('ok', 292)\n",
      "('free', 288)\n",
      "('go', 286)\n",
      "('know', 261)\n"
     ]
    }
   ],
   "source": [
    "# Statistics about emails \n",
    "print('Number of unique words', len(word_counts))\n",
    "print('')\n",
    "print('Top 10 words')\n",
    "for word in list(word_counts.most_common()[:10]):\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take 500 most common words \n",
    "vocabulary = [w[0] for w in list(word_counts.most_common()[:500])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bag of word function for pipeline\n",
    "\n",
    "def BOW(corpus, vocabulary):\n",
    "    '''\n",
    "        Function that returns a bag of words (vector the length of the vocabulary) \n",
    "        based on the corpus of texts and vocabulary data, indexed by the words.\n",
    "    '''\n",
    "    \n",
    "    bow = np.zeros((len(corpus), len(vocabulary)))\n",
    "    word2idx = dict(zip(vocabulary, list(range(len(vocabulary)))))\n",
    "    \n",
    "    for index, text in enumerate(corpus):\n",
    "        for word in text.split():\n",
    "            if word in vocabulary:\n",
    "                bow[index, word2idx[word]] = 1\n",
    "                \n",
    "    return bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = BOW(processed_corpus, vocabulary)\n",
    "dictionary_filter= {'ham': 0, 'spam': 1}\n",
    "y = [dictionary_filter[w] for w in data['v1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4825.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         747.]),\n",
       " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Look at data balance. Most of the emails are spam so models will need to possibly be balanced\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.hist(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train test split \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build logistic regression model with l1 penalty (prefers sparsity), balanced weight for unbalanced data,\n",
    "# random_state set at 42\n",
    "# Its simply learns weights for all features, then sums them and squashes the answer between 0 and 1\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(penalty = 'l1', class_weight = 'balanced', random_state = 42, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srder\\Miniconda3\\envs\\conda_env\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='warn', n_jobs=None, penalty='l1', random_state=42,\n",
       "          solver='warn', tol=0.0001, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 97.4910394265233 %\n",
      "F1 score 90.0 %\n"
     ]
    }
   ],
   "source": [
    "# Check scores on accuracy and f1 score (f1 better because it considers recall and precision scores)\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "print('Accuracy', accuracy_score(y_test, model.predict(X_test))*100, '%')\n",
    "print('F1 score', f1_score(y_test, model.predict(X_test)) * 100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now train decision tree, it learns decisions about the features (is the word \"dog\" included for example and not \"cat\")\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 96.95340501792114 %\n",
      "F1 score 87.21804511278195 %\n"
     ]
    }
   ],
   "source": [
    "# Not as good!\n",
    "print('Accuracy', accuracy_score(y_test, model.predict(X_test))*100, '%')\n",
    "print('F1 score', f1_score(y_test, model.predict(X_test)) * 100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try an ensemble (many models making the decision). In particular a random forest\n",
    "# A random forest is a bunch of decision trees train on different subsets of the data\n",
    "# The final answer takes the average answer of all the trees. We make 300 trees\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(300)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 98.02867383512545 %\n",
      "F1 score 91.60305343511452 %\n"
     ]
    }
   ],
   "source": [
    "# Even Better!\n",
    "print('Accuracy', accuracy_score(y_test, model.predict(X_test))*100, '%')\n",
    "print('F1 score', f1_score(y_test, model.predict(X_test)) * 100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 487 hams right and 61 spams right. Got 4 hams wrong and 6 spams wrong\n",
      "\n",
      "[[487   4]\n",
      " [  7  60]]\n"
     ]
    }
   ],
   "source": [
    "# Now we look to see what mistakes the network is making using a confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print('Got 487 hams right and 61 spams right. Got 4 hams wrong and 6 spams wrong')\n",
    "print('')\n",
    "print(confusion_matrix(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77\n"
     ]
    }
   ],
   "source": [
    "# Whats the longest email?\n",
    "max_len = np.max([len(email.split()) for email in processed_corpus])\n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Now we go overkill with a deep conv-LSTM style neural network with embeddings\n",
    "from keras.models import Input, Model\n",
    "from keras.layers import Dense, Embedding, Activation, LSTM, Conv1D, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stop = EarlyStopping(monitor = 'val_loss', patience = 2, mode = 'auto')\n",
    "rmsprop = RMSprop(lr = 0.0001)\n",
    "\n",
    "X_input = Input(shape = (max_len,), name = 'Input_layer')\n",
    "X_tensor = Embedding(len(vocabulary), 50, trainable = True, name = 'Embedding_layer')(X_input)\n",
    "X_tensor = Conv1D(50, 3, name = 'Conv_layer')(X_tensor)\n",
    "X_tensor = Activation('relu')(X_tensor)\n",
    "X_tensor = Dropout(0.3)(X_tensor)\n",
    "X_tensor = LSTM(50, return_sequences = False, name = 'LSTM_Layer')(X_tensor)\n",
    "X_tensor = Activation('relu')(X_tensor)\n",
    "X_tensor = Dropout(0.3)(X_tensor)\n",
    "X_output = Dense(2, activation = 'softmax', name = 'output_layer')(X_tensor)\n",
    "\n",
    "model = Model(inputs = X_input, outputs = X_output)\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = rmsprop, metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input_layer (InputLayer)     (None, 77)                0         \n",
      "_________________________________________________________________\n",
      "Embedding_layer (Embedding)  (None, 77, 50)            25000     \n",
      "_________________________________________________________________\n",
      "Conv_layer (Conv1D)          (None, 75, 50)            7550      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 75, 50)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 75, 50)            0         \n",
      "_________________________________________________________________\n",
      "LSTM_Layer (LSTM)            (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 52,852\n",
      "Trainable params: 52,852\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the emails this time\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(len(vocabulary))\n",
    "tokenizer.fit_on_texts(processed_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and pad to maximum length\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "X_tok = pad_sequences(tokenizer.texts_to_sequences(processed_corpus), max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split again but in same way using same seed\n",
    "X_train_tok, X_test_tok, y_train, y_test = train_test_split(X_tok, y, test_size = 0.1, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4512 samples, validate on 502 samples\n",
      "Epoch 1/40\n",
      "4512/4512 [==============================] - 4s 965us/step - loss: 0.5495 - acc: 0.8562 - val_loss: 0.3761 - val_acc: 0.8645\n",
      "Epoch 2/40\n",
      "4512/4512 [==============================] - 4s 783us/step - loss: 0.3588 - acc: 0.8644 - val_loss: 0.3328 - val_acc: 0.8645\n",
      "Epoch 3/40\n",
      "4512/4512 [==============================] - 4s 818us/step - loss: 0.2957 - acc: 0.8672 - val_loss: 0.2663 - val_acc: 0.8765\n",
      "Epoch 4/40\n",
      "4512/4512 [==============================] - 4s 807us/step - loss: 0.2227 - acc: 0.9229 - val_loss: 0.2048 - val_acc: 0.9422\n",
      "Epoch 5/40\n",
      "4512/4512 [==============================] - 4s 809us/step - loss: 0.1651 - acc: 0.9590 - val_loss: 0.1587 - val_acc: 0.9641\n",
      "Epoch 6/40\n",
      "4512/4512 [==============================] - 4s 781us/step - loss: 0.1213 - acc: 0.9719 - val_loss: 0.1285 - val_acc: 0.9641\n",
      "Epoch 7/40\n",
      "4512/4512 [==============================] - 4s 803us/step - loss: 0.0904 - acc: 0.9783 - val_loss: 0.1115 - val_acc: 0.9641\n",
      "Epoch 8/40\n",
      "4512/4512 [==============================] - 4s 794us/step - loss: 0.0760 - acc: 0.9820 - val_loss: 0.1043 - val_acc: 0.9701\n",
      "Epoch 9/40\n",
      "4512/4512 [==============================] - 4s 918us/step - loss: 0.0644 - acc: 0.9834 - val_loss: 0.1035 - val_acc: 0.9701\n",
      "Epoch 10/40\n",
      "4512/4512 [==============================] - 4s 914us/step - loss: 0.0599 - acc: 0.9832 - val_loss: 0.0946 - val_acc: 0.9701\n",
      "Epoch 11/40\n",
      "4512/4512 [==============================] - 4s 887us/step - loss: 0.0593 - acc: 0.9840 - val_loss: 0.0951 - val_acc: 0.9701\n",
      "Epoch 12/40\n",
      "4512/4512 [==============================] - 4s 891us/step - loss: 0.0531 - acc: 0.9849 - val_loss: 0.0899 - val_acc: 0.9761\n",
      "Epoch 13/40\n",
      "4512/4512 [==============================] - 4s 890us/step - loss: 0.0527 - acc: 0.9860 - val_loss: 0.0912 - val_acc: 0.9721\n",
      "Epoch 14/40\n",
      "4512/4512 [==============================] - 4s 886us/step - loss: 0.0503 - acc: 0.9863 - val_loss: 0.0914 - val_acc: 0.9721\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x298076d8eb8>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train deep learning model \n",
    "from keras.utils import to_categorical\n",
    "epochs = 40\n",
    "\n",
    "model.fit(X_train_tok, to_categorical(y_train), \n",
    "          epochs = epochs,\n",
    "          verbose = 1, \n",
    "          shuffle = True, \n",
    "          validation_split = 0.1, \n",
    "          callbacks = [early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "558/558 [==============================] - 0s 182us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "98.56630824372759"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best Model \n",
    "model.evaluate(X_test_tok, to_categorical(y_test))[1] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
